{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de24506d",
   "metadata": {},
   "source": [
    "## This file makes machine learning application for individual packets for Aalto University. \n",
    "### Used machine learning algorithms: RF (Random Forest) DT (Decision Trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee61070",
   "metadata": {},
   "source": [
    "###  importing relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75f859a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from numpy import array\n",
    "from random import random\n",
    "from sklearn import metrics\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB#57\n",
    "from sklearn.naive_bayes import GaussianNB#52\n",
    "from sklearn.naive_bayes import MultinomialNB#56\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import csv\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02442ca",
   "metadata": {},
   "source": [
    "### Discovering dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24231694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./dataset/FP_MAIN_PCAP.csv',\n",
       " './dataset/Threshold_0.04.csv',\n",
       " './dataset/Threshold_0.05.csv',\n",
       " './dataset/Main_ML.csv',\n",
       " './dataset/IPAssess_unique.csv',\n",
       " './dataset/Main_reduced.csv',\n",
       " './dataset/IPAssess_ML.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_the_way(path,file_format):\n",
    "    files_add = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            if file_format in file:\n",
    "                files_add.append(os.path.join(r, file))  \n",
    "    return files_add\n",
    "files_add=find_the_way('./dataset/','.csv')\n",
    "files_add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a24193f",
   "metadata": {},
   "source": [
    "### Discovering Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ba48af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def target_names():\n",
    "    name=files_add[1]        # Main Feature Set\n",
    "    df = pd.read_csv(name)\n",
    "    target_names=sorted(list(df[df.columns[-2]].unique()))\n",
    "    return target_names\n",
    "target_names=target_names()\n",
    "len(target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc0df6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['august-hub-01',\n",
       " 'blink-cam-01',\n",
       " 'blink-cam-02',\n",
       " 'blink-cam-03',\n",
       " 'geeni-awarecam-1',\n",
       " 'geeni-awarecam-2',\n",
       " 'geeni-cam-01',\n",
       " 'geeni-cam-03',\n",
       " 'geeni-doorbell-01',\n",
       " 'geeni-doorbell-02',\n",
       " 'merkury-cam-01',\n",
       " 'merkury-doorbell-01',\n",
       " 'nest-doorbell-01',\n",
       " 'nightowl-doorbell-01',\n",
       " 'nightowl-doorbell-02',\n",
       " 'ring-doorbell-02',\n",
       " 'ring-doorbell-03',\n",
       " 'schlage-lock-01',\n",
       " 'sifely-hub-01',\n",
       " 'simplisafe-d1',\n",
       " 'simplisafe-d2',\n",
       " 'smartthings-cam-01',\n",
       " 'ultraloq-hub-01',\n",
       " 'wyze-cam-01']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7853341",
   "metadata": {},
   "source": [
    "### Hyperparameters of machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2616b1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_list={\n",
    "\"DT_r\":DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=22,\n",
    "                       max_features=1.0, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, \n",
    "                       min_samples_leaf=1, min_samples_split=4,\n",
    "                       min_weight_fraction_leaf=0.0,\n",
    "                       random_state=None, splitter='best'),  \n",
    " \"Random Forest R\":RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
    "                       max_depth=27, max_features=1, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0,\n",
    "                       min_samples_leaf=1, min_samples_split=10,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=69,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcac733e",
   "metadata": {},
   "source": [
    "### This part is the main part of the file. Cross-validates the respective datasets 10-time 10-fold and prints the results (general results, class-based results and confusion matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e26daf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset         T   CV  ML alg  Acc   b_Acc Prec  Rec   F1    kap   tra-T    test-T  total   \n",
      "et/Threshold_0.04 0   1   DT_r    0.71  0.6   0.7   0.6   0.63  0.67  13.03    0.17    13.2    \n",
      "et/Threshold_0.04 0   2   DT_r    0.71  0.6   0.69  0.6   0.63  0.67  13.07    0.16    13.23   \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m clf \u001b[38;5;241m=\u001b[39m ml_list[ii]\u001b[38;5;66;03m#choose algorithm from ml_list dictionary\u001b[39;00m\n\u001b[1;32m     50\u001b[0m second\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 51\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     52\u001b[0m train_time\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m((time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39msecond)) )\n\u001b[1;32m     53\u001b[0m second\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    930\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \n\u001b[1;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 959\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    960\u001b[0m         X,\n\u001b[1;32m    961\u001b[0m         y,\n\u001b[1;32m    962\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    963\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[1;32m    964\u001b[0m     )\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    434\u001b[0m         splitter,\n\u001b[1;32m    435\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    441\u001b[0m     )\n\u001b[0;32m--> 443\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ths = open(\"dataset/threshold_0.05_ML.csv\", \"w\")\n",
    "ths.write(\"Dataset,T,CV,ML algorithm,Acc,b_Acc,Precision, Recall , F1-score, kappa ,tra-Time,test-Time,total-Time))\\n\")\n",
    "repetition=10\n",
    "\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.preprocessing import Normalizer\n",
    "print ('%-15s %-3s %-3s %-6s  %-5s %-5s %-5s %-5s %-5s %-5s %-8s %-8s%-8s'%\n",
    "           (\"Dataset\",\"T\",\"CV\",\"ML alg\",\"Acc\",\"b_Acc\",\"Prec\", \"Rec\" , \"F1\", \"kap\" ,\"tra-T\",\"test-T\",\"total\"))\n",
    "curr_file=[]\n",
    "curr_file.append(files_add[1])\n",
    "for loop in curr_file:\n",
    "    for ii in ml_list:\n",
    "        class_based_results=pd.DataFrame()#\"\" #pd.DataFrame(0, index=np.arange((len(target_names)+3)), columns=[\"f1-score\",\"precision\",\"recall\",\"support\"])\n",
    "        cm=pd.DataFrame()\n",
    "        for i in range(repetition):\n",
    "            rnd = random()\n",
    "            kfold = KFold(n_splits=10, shuffle=True, random_state=int(rnd*100))  \n",
    "            cv=0\n",
    "            df = pd.read_csv(loop)#,header=None )\n",
    "            del df[\"MAC\"] # if dataset has MAC colomn please uncomment this line\n",
    "            X =df[df.columns[0:-1]]\n",
    "            X=np.array(X)\n",
    "            df[df.columns[-1]] = df[df.columns[-1]].astype('category')\n",
    "            y=df[df.columns[-1]].cat.codes  \n",
    "            #scaler = Normalizer().fit(X)\n",
    "            #X = scaler.transform(X)\n",
    "            # summarize transformed data\n",
    "            dname=loop[7:-4]\n",
    "            X.shape\n",
    "            for train_index, test_index in kfold.split(X):\n",
    "                results_y=[]\n",
    "                X_train, X_test = X[train_index], X[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]  \n",
    "                cv+=1\n",
    "                results_y.append(y_test)\n",
    "\n",
    "\n",
    "                precision=[]\n",
    "                recall=[]\n",
    "                f1=[]\n",
    "                accuracy=[]\n",
    "                train_time=[]\n",
    "                test_time=[]\n",
    "                total_time=[]\n",
    "                kappa=[]\n",
    "                accuracy_b=[]\n",
    "                    #machine learning algorithm is applied in this section\n",
    "                clf = ml_list[ii]#choose algorithm from ml_list dictionary\n",
    "                second=time.time()\n",
    "                clf.fit(X_train, y_train)\n",
    "                train_time.append(float((time.time()-second)) )\n",
    "                second=time.time()\n",
    "                predict =clf.predict(X_test)\n",
    "                test_time.append(float((time.time()-second)) )\n",
    "\n",
    "                rc=sklearn.metrics.recall_score(y_test, predict,average= \"macro\")\n",
    "                pr=sklearn.metrics.precision_score(y_test, predict,average= \"macro\")\n",
    "                f_1=sklearn.metrics.f1_score(y_test, predict,average= \"macro\")        \n",
    "                report = classification_report(y_test, predict, target_names=target_names,output_dict=True)\n",
    "                cr = pd.DataFrame(report).transpose()\n",
    "                if class_based_results.empty:\n",
    "                    class_based_results =cr\n",
    "                else:\n",
    "                    class_based_results = class_based_results.add(cr, fill_value=0)\n",
    "                precision.append(float(pr))\n",
    "                recall.append(float(rc))\n",
    "                f1.append(float(f_1))\n",
    "                accuracy_b.append(balanced_accuracy_score( y_test,predict))\n",
    "                accuracy.append(accuracy_score(y_test, predict))\n",
    "                #clf.score(X_test, y_test))\n",
    "                #print(balanced_accuracy_score( y_test,predict))\n",
    "                #t_time.append(float((time.time()-second)) )\n",
    "                kappa.append(round(float(sklearn.metrics.cohen_kappa_score(y_test, predict, \n",
    "                labels=None, weights=None, sample_weight=None)),15))\n",
    "                print ('%-15s %-3s %-3s %-6s  %-5s %-5s %-5s %-5s %-5s %-5s %-8s %-8s%-8s' % (dname,i,cv,ii[0:6],str(round(np.mean(accuracy),2)),str(round(np.mean(accuracy_b),2)),\n",
    "                    str(round(np.mean(precision),2)), str(round(np.mean(recall),2)),str(round(np.mean(f1),2)), \n",
    "                    str(round(np.mean(kappa),2)),str(round(np.mean(train_time),2)),str(round(np.mean(test_time),2)),str(round(np.mean(test_time)+np.mean(train_time),2))))\n",
    "                lines=(str(dname)+\",\"+str(i)+\",\"+str(cv)+\",\"+str(ii)+\",\"+str(round(np.mean(accuracy),15))+\",\"+str(round(np.mean(accuracy_b),15))+\",\"+str(round(np.mean(precision),15))+\",\"+ str(round(np.mean(recall),15))+\",\"+str(round(np.mean(f1),15))+\",\"+str(round(np.mean(kappa),15))+\",\"+str(round(np.mean(train_time),15))+\",\"+str(round(np.mean(test_time),15))+\",\"+str(round(np.mean(test_time)+np.mean(train_time),15))+\"\\n\")\n",
    "\n",
    "                ths.write (lines)\n",
    "\n",
    "                df_cm = pd.DataFrame(confusion_matrix(y_test, predict))\n",
    "                results_y.append(predict)\n",
    "                if cm.empty:\n",
    "                    cm =df_cm\n",
    "                else:\n",
    "                    cm = cm.add(df_cm, fill_value=0)\n",
    " \n",
    "        print(class_based_results/100) \n",
    "        cm=cm/100\n",
    "        graph_name=\"confusion matrix\" +str(ii)       \n",
    "        plt.figure(figsize = (20,14))\n",
    "        sns.heatmap(cm,xticklabels=target_names, yticklabels=target_names, annot=True)\n",
    "        plt.savefig(graph_name,bbox_inches='tight')#, dpi=400)\n",
    "        plt.show()\n",
    "        #print(cm)\n",
    "        print(\"\\n\\n\\n\") \n",
    "ths.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b032d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
